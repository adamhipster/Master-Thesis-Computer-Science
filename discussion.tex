\chapter{Discussion}

% Repeat research question
The questions from the beginning were: what is the relationship between XIMPEL and education? And how does XIMPEL need to be improved for it to better serve education? These questions have been treated in a slightly more general sense by applying the question to hypermedia. Even though XIMPEL is not a strict hypermedia framework, in this thesis it has been treated as such. The philosophy of developing XIMPEL is one where pragmatism and interactivity is favored over the ideals of hypermedia. Therefore, it is quite hard to pinpoint what XIMPEL really is. Not to forget, it is also a framework to gain a poor man's immersion for games \cite{eliens2007}. Perhaps it is best described as a hypermedia framework with gamification possibilities. With that said, it is clear it is heavily and mostly inspired on the ideals that hypermedia had in the beginning phases of the world wide web. 

It is with pragmatism that the questions about education were implicitly answered. The relationship between XIMPEL and education is the creation of online education. It has been possible to recreate a lot of psychology massive online open courses (MOOCs) with XIMPEL since all they need are: video lectures, quizzes, scoring quizzes and text. The Zaanse Schans video shows one way of how this could be implemented. However, it would not have been possible to recreate a computer science course. This is why the terminal extension has been built in exploration 1, to explore and prototype how it should be done. Prototyping computer science courses with a hypermedia framework is a new way to look at computer science education. Another implication with parallel media play is that XIMPEL looks like a LaTeX for PowerPoint, meaning that it can be used for general presentations. I personally tested this to teach my mother about file systems, it also had quizzes to test whether she understood me. One could create this with PowerPoint and now it is also possible to with XIMPEL.

However, only having a terminal window open without anything else is not really informative. The second question on how XIMPEL needed to be improved for educational purposes answered itself in two ways in exploration 2. First of all, the hypermedia ideal should be relaxed and be used as inspiration, as it already was by the XIMPEL developers. This allows for the development of, for example, a `<terminal>` tag as shown in exploration 1. Second, XIMPEL needed the ability to play parallel media. This feature has also been identified as future work by Stefan Bruins, who ported XIMPEL from ActionScript to JavaScript. 

Now with these two explorations both questions have been answered. One could always research deeper into a question but the theme of this thesis was exploring XIMPEL (and hypermedia), not answering research questions as deeply as possible. This also was needed since research on hypermedia seems to be a bit forgotten. The decision to look at another question rose to the surface in the form of recreating XIMPEL in React in exploration 3. Switching to different questions reveals more about the nature of hypermedia, which could lead to more potential avenues of new research, which might mean that the research topic will be looked after a bit more. In short: asking more questions is its own contribution

The question that came up during exploration 1 and 2 is: since the XIMPEL playlist almost looks like a return statement from a render method in ReactJS, would it mean that ReactJS would help the development of XIMPEL? The idea here is that it may help since XIMPEL has something in common with the core philosophy of React: every tag has its own rules. Moreover, would the React ecosystem and best practices help the development of XIMPEL? 

The answer is: React does help. It also does not. It helps in the sense that mapping components to XML tags makes the development of XIMPEL easier to reason about, mostly because this mapping is explicit in the architecture of the React version of XIMPEL. Another advantage is that the XML attributes are already parsed as props per React component. On another note, the ability to write React Native and have cross-browser compatibility without thinking too much about it is exciting. However, two areas of difficulty in the beginning for a new React developer are the fine-grained understanding of lifecycle methods and best coding practices in React. Especially if a developer does not have knowledge on both of these topics, it will take some time to become productive. The biggest disadvantage is when components become too complex and they need to be compartmentalized. This has happened a little bit by creating specific media type components (e.g. `Image`) as a render prop for a `MediaType` component that had time tracking abilities which all specific media type components needed. All media types have common tasks (e.g. time tracking), but this is not expressed in the XML playlist, which breaks the one component mapped to one XML tag abstraction a bit.

The answer to React ecosystem question is a definitive yes since the ecosystem allowed for ES6 and using an XML parser in the form of a library. Writing ES6 helps because combined with React it forces one to write quality code, which is the intention of the React library developers\footnote{A good example of that this really is their intention is seen in their update on async rendering. See: \url{https://reactjs.org/blog/2018/03/27/update-on-async-rendering.html}}. Having an XML parser that does what one wants it to do means it saves writing code. Furthermore, the technology is relevant today which means that motivated students could learn a relevant technology
\footnote{This used to be the case for when XIMPEL was written in ActionScript and it eventually faded with the rise of HTML5. This may happen again as well, especially since Adobe fought hard to keep it alive and still failed. However, there is hope it may not since Facebook is behind React and it is more invested in creating amazing applications for the web.}. 
It ties back to the first question as well: developing with XIMPEL helps education, and studying the source code of the framework is educational as well. Credits have to be given to Anton Eli\"ens for this idea, since he has nudged students into studying the ActionScript code of XIMPEL when I took his class -- and I did in fact study it.
To conclude for exploration 3: while React on itself would not have been enough of an improvement, combined with its ecosystem it (perhaps) is.

Does this mean that all XIMPEL development need to happen in React? This depends very much on the team of the XIMPEL developers and mostly their personal goals. If the XIMPEL developers are neutral, then yes. If they are not for some non-technical reason, then perhaps not. It could also be that two versions co-exist of XIMPEL which is fine. XIMPEL has been mostly developed in an explorative user-centric way after all\cite{winoe2018}. 

There is no connection from exploration 3 to exploration 4. As stated before in this thesis I was daydreaming. It furthermore is the topic which is removed from hypermedia as much as possible. It is also the first exploration where the conceptualization of ideas has played a much more important role than pure implementation. The question was: how to measure frustration within the users of XIMPEL? A similar question has been asked for engagement, albeit a lot less emphasized. 

In this exploration the minimal conditions needed to capture the data has been presented. One of these minimal conditions is that facial expressions are captured since mouse data is not enough. Furthermore, research in capturing frustration via facial expressions seemed confusing at best, which is why capturing anger and sadness seem to be a better way to capture frustration. Not all instances of anger and sadness have to do with frustration, but anger and sadness are possible consequences of frustration\cite{funches2011, yamagishi2012, szasz2011, roest2015}, are more universal\cite{ortony1990} and also more well-studied. 

Regarding the other metrics, some hypotheses have been formulated on how to detect frustration there. Research on it has been scarce so it has been a mixture of literature and my own thoughts on how to detect it. Future work of simply training models have been eluded to.

Exploration 5 and 6 have been natural consequences of the result in exploration 2: the ability to play multiple media items. In exploration 5 it has been explored what the consequences are for time scrubbing. Not all design issues with time scrubbing come from the parallel media player, the biggest design issue starts to appear when one wants to time scrub between subjects. The parallel media player does interact with the other design issues and makes them more complicated by default.

Exploration 6 asked the question on how to implement a media type that survives a subject change. Normally, in XIMPEL it is impossible for media to survive a subject change. Even if the media would be played in the new subject as well it would suffer from refreshing issues and rendering issues. It furthermore would forget its state, which for a YouTube media type might be simple enough to save, but for a terminal media type this might not be the case. This feature is called partial subject refresh. Even though it is actually a complete subject refresh, \textit{it seems} that it is not, hence the name. This question could not have been asked if XIMPEL did not play multiple media types within a subject.

And now we are here. To summarize these are the questions that have been asked:
\begin{itemize}
    \item what is the relationship between XIMPEL and education? 
    \item How does XIMPEL need to be improved for it to better serve education? 
    \item Does React and its ecosystem help for developing XIMPEL? If so, how?
    \item How does one measure and classify frustration and engagement in hypermedia frameworks?
    \item How should a time scrubbing feature be designed in XIMPEL?
    \item How does a media type developer implement a partial subject refresh in its media type?
\end{itemize}

In the style of the `whatis` command, here are one line answers:
\begin{itemize}
    \item The creation of MOOCs.
    \item It needs the ability to play parallel media and needs to have built-in applications as a tag.
    \item Yes, it helps because of useful libraries, better development practices, cross-browser compatibility and the possibility to create mobile applications with a XIMPEL playlist.
    \item By capturing data from the mouse, what the user is viewing now and his or her facial expression.
    \item It depends, there are a variety of ways and it is not clear which one has a better user experience.
    \item By interjecting the model of the media item in the subject which has the `leadsTo` of the subject on which you want the media type to stop.
\end{itemize}

\section{Future Work}

% Server-side
XIMPEL is a frontend framework. It used to have no connection to any backend. In some of the explorations (1 and 4) it needed a connection with a backend. In both cases the solution has been to create a NodeJS server and use websockets or XHR to connect with it. Any developer who has a background in NodeJS or any other server-side micro framework will find this relatively easy to do. Therefore, future work could go into specifically developing XIMPEL so that it would fit with a microservice architecture. It could also be researched what the drawbacks and advantages are. Independently, in Norway some backend programming has been done in Flask, which at the very least hints at the idea that it is an intuitive architecture to have.

% Fundamental
A more fundamental area of research and development is to make a hypermedia or hypermedia-like framework that focuses on web developers. HTML5 has made hypermedia applications more approachable through the use of HTML, CSS and JavaScript. More specifically, the video and audio HTML tags and their respective JavaScript APIs make this possible. What has not been made easy is the concept of overlays, which is what forms the hyper part in \textit{hyper}media. So a library that focuses on this might help. There are already solutions out there\footnote{\url{https://github.com/mrhenry/overlay-js} and \url{https://www.npmjs.com/package/videojs-overlay}}. However, they do not focus on hypermedia. They focus on more specific use cases.

% Synchronization sequence player (play next) video
Other fundamental future research is a literature review on media synchronization. The AHM and SMIL made this a huge topic. XIMPEL does not make this a huge topic at all. However, the justification regarding not making that a huge topic seems to be lacking. Hence, a literature review may help to elucidate what justifications there are for either perspective, and perhaps there are more perspectives to consider.

% Exploration 4 and 5
Partially fundamental and partially not, the implementation of exploration 4 (classifying frustration) and 5 (implementing time scrubbing) are future work. Both are bachelor or, depending on how far one goes, master theses on their own. Other than the further implementation of exploration 4, there is more future work regarding that area (see the future work section of exploration 4). Exploration 5 has its own challenge in that it is mostly a requirements issue and design issue, which falls in the domain of human-computer interaction.

% Web components
The first paragraph about fundamental future research was about focusing on web developers. A similar brand of future work would be to recreate XIMPEL through the use of web components. This would not mean that XIMPEL would be exactly the same. The benefit that one would attempt to have using this approach is the ability to create a playlist or several playlist within an HTML file. This would be useful for web developers who want the full ability of HTML, JavaScript and CSS but also want the functionality that XIMPEL tags provide. Another possible way to achieve this is reuse the media type components from XIMPEL React and develop a ReactJS application, which may very well be a much quicker way to achieve this since the media type components already exist -- they may need to be adapted a little.

% More interdisciplinarity
Moving away from fundamental research and the web, a collaboration between media studies researchers and computer scientists could be made. The amount of knowledge about media from a more conceptual point of view taught to computer science students is close to zero. Because of this, people with a background in computer science know the technicalities of media but not really what it is. It is likely that this is also the case for hypermedia. Interdisciplinary research on the bounaries between (hyper)media and applications could be done. Or maybe it is not research but simply cross-over lectures at universities. For example, teaching XIMPEL to media students and having a discussion with them about (hyper)media.

From a more technical point of view the idea of MISSS challenges the idea of subjects. There are different ideas to think about hypermedia, for example, the AHM thought about media items needed to be put in different tracks, akin to musical instrument tracks in a digital audio workstation such as GarageBand, Cubase or Logic Pro. A question could be: how can one fully re-imagine a hypermedia framework from the ground up?

% Where does XIMPEL need to go for education?
Regarding education, it is simple what needs to be done for XIMPEL. Content is king. Right now XIMPEL has no king. Therefore, XIMPEL needs content, educational content. This will show how usable XIMPEL is right now to current XIMPEL authors. Strengths and weaknesses will surface. It is clear that XIMPEL will occupy a niche in the prototyping space. The real question is: could it also occupy a space in production, and if so, is that already the case or does it need to be improved?

% Implications parallel media player
The thesis itself showed a lot of implications regarding the parallel player. More future studies could be done on focusing what the implications of sequential media playback, parallel media playback and parallel media playback including applications are. One could say that this thesis is a contribution to that, but there is more to explore. Especially mathematically, for example, what if all time scrubbers knew the playback position of all the other objects it has a relationship with, how many connections would there be? Take for example, a graph scrub time graph, a global subject scrub time line, and 5 media items within that subject. 7 time scrubbers in total being connected to each other is $n(n-1)/2$ with $n=7$ so it is 21. Perhaps the mathematical implications are already solved problems in mathematics, but they are not yet uncovered within the realm of hypermedia.

% Conditional media items
Another area of future research regarding media playback is to introduce a third type of media playback, which is the optional media item. This feature exists in SMIL \cite{SMIL_lecture}. Though before implementing this an analysis needs to be done whether optional media playback can now be modelled with a combination of MISSS, subjects and conditional subject switches via a score. It may be the case that it already is possible since the conditionality can be modelled via scores and different subjects. Despite the fact that it may be possible, another related question is if it is possible to model the same level of fine-grained control since SMIL has it on a media item basis and with XIMPEL it is one level up: on a subject level basis.

% Hypermedia and gamification
XIMPEL is an amazing framework to do gamification studies with regarding score. At the time of writing my thesis I did not realize this, otherwise I would have done it (if there is a gap in the literature). Here is why: current gamification focuses a lot on points. And in my experience non-game designers who do not play digital games believe that simply showing points is enough. With XIMPEL the claim of showing points being motivational in itself can easily be tested. They can be tested against: no points and points with meaning. What are points with meaning in XIMPEL? Simple, points that are related to conditional subject switches. When points are connected to subject switches they inherently mean something, because points are part of a mechanism of determining what content a user gets to see. This study could be done in collaboration with psychologists and would have three testable conditions: no points, showing points, connecting points to conditionals (which is basically the equivalent of an if-statement).

% Also XIMPEL and SVG animations aren't mentioned
Gamification and animation go hand in hand. SMIL has animation capabilities. It needs to be researched whether XIMPEL could use that specific language as a media plugin, or that SVG is a better format. Adding animation capabilities to XIMPEL will create a richer experience to users. It furthermore may be needed for hypermedia presentations or applications used in production, since some of these may need a certain type of polish that only animation can provide.

% XIMPEL and VR and Ar aren't mentioned
Other than animation, another form of media that this thesis did not look at are augmented reality, mixed reality and virtual reality. It could be researched how they intersect with hypermedia and perhaps added to the framework. A simple example is: having a smartphone that is aware of your location, and then overlaying some piece of information next to the designated landmark of said location on the smartphone. This research could go hand in hand with XIMPEL being ported for binary mobile applications.

Finally, this section could be a thesis on its own. A lot of topics have been touched in this thesis which all was about exploring XIMPEL and exploring the nature of hypermedia. The final future work recommendation is the one that may enjoy a high priority since it will elevate XIMPEL to another device type: mobile. Creating a version in which it is possible to create mobile phone applications with XIMPEL seems the most interesting use case of using a hypermedia framework like XIMPEL, simply because it makes a certain subclass of mobile phone applications a lot easier to make. Therefore, XIMPEL needs to be ported to React Native. An amazing example of this is: tablet questionnaire applications for psychology research (ok, 2 device types!). There is a real need for this. Take the Vrije Universiteit as an example: it employs its own iOS programmers to create such applications for psychologists and education researchers. An example of such an application is the SIVT iPad app (Sociale Informatie Verwerkings Test, English: Social Information Processing Test). It is a test for young children with an IQ between 50 to 85 to see how well they recognize certain social situations. For example, they see a clip of a social situation and they ask a question about it. With XIMPEL it would not take a team of developers a year building it. It would be a month.